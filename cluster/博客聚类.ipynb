{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 获取url对应的标题和单词统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import re\n",
    "\n",
    "def get_word_counts(url):\n",
    "    d = feedparser.parse(url)\n",
    "    wc = {}\n",
    "\n",
    "    # 所有文章\n",
    "    for e in d.entries:\n",
    "        if 'summary' in e: summary = e.summary\n",
    "        else: summary = e.description\n",
    "\n",
    "        # 提取文章中的词\n",
    "        words = get_words(e.title + ' ' + summary)\n",
    "        for word in words:\n",
    "            wc.setdefault(word, 0)\n",
    "            wc[word] += 1\n",
    "    return d.feed.title, wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_words(html):\n",
    "    # 移除html标签\n",
    "    txt = re.compile(r'<[^>]+>').sub('', html)\n",
    "    # 利用非字母字符拆分单词\n",
    "    words = re.compile(r'[^A-Z^a-z]+').split(txt)\n",
    "    \n",
    "    return [word.lower() for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 对订阅列表中的所有链接进行单词统计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 由于gfw的原因，很多feedlist无法访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse feed http://feeds.feedburner.com/37signals/beMH\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/blogspot/bRuz\n",
      "\n",
      "Failed to parse feed http://battellemedia.com/index.xml\n",
      "\n",
      "Failed to parse feed http://blog.guykawasaki.com/index.rdf\n",
      "\n",
      "http://blog.outer-court.com/rss.xml\n",
      "\n",
      "Failed to parse feed http://feeds.searchenginewatch.com/sewblog\n",
      "\n",
      "Failed to parse feed http://blog.topix.net/index.rdf\n",
      "\n",
      "Failed to parse feed http://blogs.abcnews.com/theblotter/index.rdf\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/ConsumingExperienceFull\n",
      "\n",
      "Failed to parse feed http://flagrantdisregard.com/index.php/feed/\n",
      "\n",
      "Failed to parse feed http://featured.gigaom.com/feed/\n",
      "\n",
      "Failed to parse feed http://gizmodo.com/index.xml\n",
      "\n",
      "Failed to parse feed http://gofugyourself.typepad.com/go_fug_yourself/index.rdf\n",
      "\n",
      "Failed to parse feed http://googleblog.blogspot.com/rss.xml\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/GoogleOperatingSystem\n",
      "\n",
      "Failed to parse feed http://headrush.typepad.com/creating_passionate_users/index.rdf\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/instapundit/main\n",
      "\n",
      "Failed to parse feed http://jeremy.zawodny.com/blog/rss2.xml\n",
      "\n",
      "Failed to parse feed http://joi.ito.com/index.rdf\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/Mashable\n",
      "\n",
      "Failed to parse feed http://michellemalkin.com/index.rdf\n",
      "\n",
      "Failed to parse feed http://moblogsmoproblems.blogspot.com/rss.xml\n",
      "\n",
      "http://newsbusters.org/node/feed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apcount = {}\n",
    "wordcounts = {}\n",
    "feedlist = [line for line in open('feedlist.txt')]\n",
    "for feedurl in feedlist:\n",
    "    try:\n",
    "        title, wc = get_word_counts(feedurl)\n",
    "        wordcounts[title] = wc\n",
    "        for word, count in wc.items():\n",
    "            apcount.setdefault(word, 0)\n",
    "            if count > 1:\n",
    "                apcount[word] += 1\n",
    "        print('%s' % feedurl)\n",
    "    except:\n",
    "        print('Failed to parse feed %s' % feedurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 只有出现频率在10%~50%的单词会被记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wordlist = []\n",
    "for w, bc in apcount.items():\n",
    "    frac = float(bc) / len(feedlist)\n",
    "    if frac > 0.1 and frac < 0.5:\n",
    "        wordlist.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 将每篇订阅的词频向量合并为词频矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out = open('blogdata.csv','w')\n",
    "# 第一行\n",
    "out.write('Blog')\n",
    "for word in wordlist: out.write(',%s' % word)\n",
    "out.write('\\n')\n",
    "# 后面每行第一个为blog名称，后面为词频\n",
    "for blog, wc in wordcounts.items():\n",
    "    print(blog)\n",
    "    out.write(blog)\n",
    "    for word in wordlist:\n",
    "        if word in wc: out.write(',%d' % wc[word])\n",
    "        else: out.write(',0')\n",
    "    out.write('\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 分层聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path='./blogdata.csv'):\n",
    "    data = pd.read_csv(path)\n",
    "    titles = np.array(data['Blog'])\n",
    "    # 返回numpy数组\n",
    "    return titles, np.array(data)[:, 1:]\n",
    "\n",
    "feed_titles, data = load_data()\n",
    "print(data.shape, feed_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 定义距离：1-皮尔森相关系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def pearson_distance(e1, e2):\n",
    "    sum1 = sum(e1)\n",
    "    sum2 = sum(e2)\n",
    "    \n",
    "    sum_of_square1 = sum([pow(w, 2) for w in e1])\n",
    "    sum_of_square2 = sum([pow(w, 2) for w in e2])\n",
    "    \n",
    "    n = len(e1)\n",
    "    sum12 = sum([e1[i] *e2[i] for i in range(n)])\n",
    "    \n",
    "    num = sum12 - (sum1 * sum2 / n)\n",
    "    den = sqrt((sum_of_square1 - pow(sum1, 2) / n) * (sum_of_square2 - pow(sum2, 2) / n))\n",
    "    \n",
    "    if den == 0: return 0\n",
    "    return 1 - num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(pearson_distance(data[3], data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 创建聚类class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class bicluster:\n",
    "    def __init__(self, vec, left=None, right=None, distance=0, id=None):\n",
    "        self.vec = vec\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.distance = distance\n",
    "        self.id = id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 两两类别合并，构造成树形结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hcluster(data, distance=pearson_distance):\n",
    "    dis = {}\n",
    "    current_id = -1\n",
    "    # 初始化：每个点各成一类\n",
    "    clust = [bicluster(data[i], id=i) for i in range(data.shape[0])]\n",
    "    \n",
    "    while len(clust) > 1:\n",
    "        \n",
    "        # 寻找最近的两个类\n",
    "        closest_pair = (0, 1)\n",
    "        closest_dis = distance(clust[0].vec, clust[1].vec)\n",
    "        \n",
    "        for i in range(len(clust)):\n",
    "            for j in range(i + 1, len(clust)):\n",
    "                if (clust[i].id, clust[j].id) not in dis:\n",
    "                    tmp_dis = distance(clust[i].vec, clust[j].vec)\n",
    "                if tmp_dis < closest_dis:\n",
    "                    closest_pair = (i, j)\n",
    "                    closest_dis = tmp_dis\n",
    "        \n",
    "        x, y = closest_pair[0], closest_pair[1]\n",
    "        mid_vec = [(clust[x].vec[i] + clust[y].vec[i]) / 2 for i in range(data.shape[1])]\n",
    "        # 两个类合并成新类\n",
    "        newcluster = bicluster(mid_vec, left=clust[x], right=clust[y], distance=closest_dis, id=current_id)\n",
    "        clust.append(newcluster)\n",
    "        current_id -= 1\n",
    "        \n",
    "        clustx = clust[x]\n",
    "        clusty = clust[y]\n",
    "        # 删除合并前的两个类\n",
    "        clust.remove(clustx)\n",
    "        clust.remove(clusty)\n",
    "        # print(x, y)\n",
    "        # ls = [clust[i].id for i in range(len(clust))]\n",
    "        # print(ls)\n",
    "    # 返回聚类的树根\n",
    "    return clust[0]\n",
    "\n",
    "root = hcluster(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 输出聚类树形结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_tree(root, depth=0):\n",
    "    for i in range(3 * depth): print(' ', end=\"\")\n",
    "    \n",
    "    if root.id < 0: print('--')\n",
    "    else: print(feed_titles[root.id])\n",
    "    \n",
    "    if root.left is not None: print_tree(root.left, depth + 1)\n",
    "    if root.right is not None: print_tree(root.right, depth + 1)\n",
    "\n",
    "print_tree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def kcluster(data, distance=pearson_distance, k=3):\n",
    "    # 在向量空间中随机k个中心点\n",
    "    vec_range = [(min([data[i][j] for i in range(data.shape[0])]), max([data[i][j] for i in range(data.shape[0])])) \n",
    "                 for j in range(data.shape[1])]\n",
    "    centers = []\n",
    "    random.seed()\n",
    "    for i in range(k):\n",
    "        center = [random.random() * (vec_range[j][1] - vec_range[j][0]) + vec_range[j][0] for j in range(data.shape[1])]\n",
    "        centers.append(center)\n",
    "    # 初始化点的类别标签\n",
    "    labels = {}\n",
    "    for i in range(data.shape[0]):\n",
    "        labels[i] = -1\n",
    "    #print(data)\n",
    "    while 1:\n",
    "        # 标记是否有中心变化\n",
    "        fg = False\n",
    "        # 计算每个点所属分类\n",
    "        for i in range(data.shape[0]):\n",
    "            min_dis = distance(centers[0], data[i])\n",
    "            min_num = 0\n",
    "            for j in range(1, k):\n",
    "                tmp_dis = distance(centers[j], data[i])\n",
    "                if tmp_dis < min_dis:\n",
    "                    min_dis = tmp_dis\n",
    "                    min_num = j\n",
    "            if labels[i] != min_num:\n",
    "                fg = True\n",
    "                labels[i] = min_num\n",
    "        # 更新中心点\n",
    "        if fg == False: break\n",
    "        \n",
    "        sumv = [[0] * data.shape[1]] * k\n",
    "        nums = [0] * k\n",
    "        for i in range(data.shape[0]):\n",
    "            nums[labels[i]] += 1\n",
    "            for j in range(data.shape[1]):\n",
    "                sumv[labels[i]][j] += data[i][j]\n",
    "        \n",
    "        for i in range(k):\n",
    "            if nums[i] != 0:\n",
    "                for j in range(data.shape[1]):\n",
    "                    centers[i][j] = sumv[i][j] / nums[i]\n",
    "        print('sumv: ', sumv)\n",
    "        print('centers: ', centers)\n",
    "    return labels\n",
    "\n",
    "res = kcluster(data)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
